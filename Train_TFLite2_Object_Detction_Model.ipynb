{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmic-smeraldo001/files/blob/main/Train_TFLite2_Object_Detction_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF8ysCfYKgTP"
      },
      "source": [
        "# TensorFlow Lite Object Detection API in Colab\n",
        "**Author:** Evan Juras, [EJ Technology Consultants](https://ejtech.io)\n",
        "\n",
        "**Last updated:** 1/28/23\n",
        "\n",
        "**GitHub:** [TensorFlow Lite Object Detection](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi)\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This notebook uses [the TensorFlow 2 Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) to train an SSD-MobileNet model or EfficientDet model with a custom dataset and convert it to TensorFlow Lite format. By working through this Colab, you'll be able to create and download a TFLite model that you can run on your PC, an Android phone, or an edge device like the Raspberry Pi.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://s3.us-west-1.amazonaws.com/evanjuras.com/img/CoinDetectorDemo.gif\" height=\"360\"><br>\n",
        "<i>Custom SSD-MobileNet-FPNLite model in action!</i>\n",
        "</p>\n",
        "\n",
        "I also made a YouTube video that walks through this guide step by step. I use a coin detection model as an example for the video. I recommend following along with the video while working through this notebook.\n",
        "\n",
        "<p align=center>\n",
        "<a href=\"https://www.youtube.com/watch?v=XZ7FYAMCc4M\" target=\"_blank\"><img src=\"https://s3.us-west-1.amazonaws.com/evanjuras.com/img/thumbnail-tflite-colab-1.png\" height=\"240\"><br>\n",
        "<i>Click here to go to the video!</i></a>\n",
        "</p>\n",
        "\n",
        "**Important note: This notebook will be continuously updated to make sure it works with newer versions of TensorFlow. If you see any differences between the YouTube video and this notebook, always follow the notebook!**\n",
        "\n",
        "### Working in Colab\n",
        "Colab provides a virtual machine in your browser complete with a Linux OS, filesystem, Python environment, and best of all, a free GPU. It comes with most TensorFlow backend requirements (like CUDA and cuDNN) pre-installed. Simply click the play button on sections of code in this notebook to execute them on the virtual machine.\n",
        "\n",
        "> *Note: Make sure you're using a GPU-equipped machine by going to \"Runtime\" -> \"Change runtime type\" in the top menu bar, and then selecting \"GPU\" from the Hardware accelerator dropdown.*\n",
        "\n",
        "This Colab notebook uses TensorFlow 2. If you'd like to use TensorFlow 1, please see my [TF1 Colab notebook](https://colab.research.google.com/github/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Train_TFLite1_Object_Detection_Model.ipynb).\n",
        "\n",
        "### Navigation\n",
        "This is a long notebook! Each step of the training process has its own section. Click the arrow next to the heading for each section to expand it. You can use the table of contents in the left sidebar to jump from section to section."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.&nbsp;Gather and Label Training Images"
      ],
      "metadata": {
        "id": "4VAvZo8qE4u5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag0qD4XiBDcz"
      },
      "source": [
        "Before we start training, we need to gather and label images that will be used for training the object detection model. A good starting point for a proof-of-concept model is 200 images. The training images should have random objects in the image along with the desired objects, and should have a variety of backgrounds and lighting conditions.\n",
        "\n",
        "Watch the YouTube video below for instructions and tips on how to gather and label images for training an object detection model.\n",
        "\n",
        "<p align=center>\n",
        "<a href=\"https://www.youtube.com/watch?v=v0ssiOY6cfg\" target=\"_blank\"><img src=\"https://s3.us-west-1.amazonaws.com/evanjuras.com/img/thumbnail-capture-label-data.png\" height=\"240\"><br>\n",
        "<i>Watch this video to learn how to capture and label images.</i></a>\n",
        "</p>\n",
        "\n",
        "When you've finished gathering and labeling images, you should have a folder full of images and corresponding .xml data annotation file for each image. An example of a labeled image and the image folder for my coin detector model are shown below.\n",
        "\n",
        "![](https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/doc/labeled_image_example2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.&nbsp;Install TensorFlow Object Detection Dependencies"
      ],
      "metadata": {
        "id": "sxb8_h-QFErO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7EOtpvlLeS0"
      },
      "source": [
        "First, we'll install the TensorFlow Object Detection API in this Google Colab instance. This requires cloning the [TensorFlow models repository](https://github.com/tensorflow/models) and running a couple installation commands. Click the play button to run the following sections of code.\n",
        "\n",
        "The latest version of TensorFlow this Colab has been verified to work with is TF v2.8.0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ypWGYdPlLRUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c50033-5cbe-463a-979c-92ed922f5f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Cython 3.0.11\n",
            "Uninstalling Cython-3.0.11:\n",
            "  Successfully uninstalled Cython-3.0.11\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 4305, done.\u001b[K\n",
            "remote: Counting objects: 100% (4305/4305), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3324/3324), done.\u001b[K\n",
            "remote: Total 4305 (delta 1207), reused 2096 (delta 908), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (4305/4305), 53.17 MiB | 29.87 MiB/s, done.\n",
            "Resolving deltas: 100% (1207/1207), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the tensorflow models repository from GitHub\n",
        "!pip uninstall Cython -y # Temporary fix for \"No module named 'object_detection'\" error\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6QPmVBSlLTzM"
      },
      "outputs": [],
      "source": [
        "# Copy setup files into models/research folder\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "#cp object_detection/packages/tf2/setup.py ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\n",
        "import re\n",
        "with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open('/content/models/research/setup.py', 'w') as f:\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('tf-models-official>=2.5.1',\n",
        "               'tf-models-official==2.8.0', s)\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "NRBnuCKjM4Bd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OLDnCkLLwLr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5efa1a91-5075-4bac-9a69-f0c721445e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.3\n",
            "  Downloading PyYAML-5.3.tar.gz (268 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/268.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.2/268.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3-cp310-cp310-linux_x86_64.whl size=44244 sha256=ce2253a1055d34b0c4c608d1a8f0be803fab33a3d1b7ea2ae4d91c3f30ef1fa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/72/68/a263cfc14175636cf26bada99f13b735be1b60a11318e08bfc\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.10.0 requires pyyaml>=5.3.1, but you have pyyaml 5.3 which is incompatible.\n",
            "flax 0.8.5 requires PyYAML>=5.4.1, but you have pyyaml 5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyyaml-5.3\n",
            "Processing ./models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object_detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object_detection==0.1)\n",
            "  Downloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (11.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.8.0)\n",
            "Collecting Cython (from object_detection==0.1)\n",
            "  Downloading Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting contextlib2 (from object_detection==0.1)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\n",
            "Collecting lvis (from object_detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Collecting tf-models-official==2.8.0 (from object_detection==0.1)\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tensorflow_io (from object_detection==0.1)\n",
            "  Downloading tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.5.0)\n",
            "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (2.155.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.6.17)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.26.4)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.10.0.84)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n",
            "Collecting seqeval (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-addons (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.9.7)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Collecting tensorflow-text~=2.8.0 (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tensorflow~=2.8.0 (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n",
            "Collecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.10.12)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cloudpickle~=2.2.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.25.5)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\n",
            "Collecting sortedcontainers>=2.4.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow<17.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.7)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.55.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.22.3)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (2024.12.14)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (6.2.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.10)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.4.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow~=2.8.0 (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow-2.8.3-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "  Downloading tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "  Downloading tensorflow-2.8.1-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.17.0)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras (from object_detection==0.1)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.8.0->object_detection==0.1) (2.17.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.8.0->object_detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.8.0->object_detection==0.1) (1.6.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (1.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.45.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (3.21.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (5.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object_detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object_detection==0.1) (3.5.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.7)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.6.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.16)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.0.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tensorflow-2.8.1-cp310-cp310-manylinux2010_x86_64.whl (498.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: object_detection, avro-python3, crcmod, dill, hdfs, seqeval, docopt\n",
            "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697355 sha256=7d6f2d77aaeb8d14ac1b852124d9a9fbfb4d9b71541a0329b8f757c36658e6a3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pb6rjm8c/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43994 sha256=eae170fb2b817206ddf7350f1bb6c55fc5dd30d4e718b9c74ac54f6478129f6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=2006c8d66e3a07e8162b5be9cee771cb58790caad6396fdbbdbf1e1558a35315\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=f1fafb7cb7f87fdf8d0bf5bb8c9c0b9f712446d53e25f28799039586088b6382\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=37f8989f57bc87ff7df7cfbabfc33130b6582584127991c3703e8a4f1c460d2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=a3540dd73591debeb2843e26d4978d2484e8515c51478c8ea1f054f2aa1b4bd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=b62c38226757ddebef4d66aad60e851b8d85c3e305a41a0ad303e1bd3d714305\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object_detection avro-python3 crcmod dill hdfs seqeval docopt\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-plugin-wit, sortedcontainers, keras, docopt, crcmod, zstandard, typeguard, tf-keras, tensorflow-model-optimization, tensorflow_io, tensorboard-data-server, redis, pyparsing, pyarrow-hotfix, pyarrow, portalocker, objsize, keras-preprocessing, jsonpickle, grpcio, fasteners, fastavro, dnspython, dill, Cython, contextlib2, colorama, cloudpickle, avro-python3, tensorflow-addons, sacrebleu, pymongo, pydot, hdfs, seqeval, lvis, google-auth-oauthlib, tensorboard, apache-beam, tensorflow, tensorflow-text, tf-models-official, object_detection\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.0\n",
            "    Uninstalling pyparsing-3.2.0:\n",
            "      Successfully uninstalled pyparsing-3.2.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.0.1\n",
            "    Uninstalling jsonpickle-4.0.1:\n",
            "      Successfully uninstalled jsonpickle-4.0.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.68.1\n",
            "    Uninstalling grpcio-1.68.1:\n",
            "      Successfully uninstalled grpcio-1.68.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.3\n",
            "    Uninstalling pydot-3.0.3:\n",
            "      Successfully uninstalled pydot-3.0.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "dask 2024.10.0 requires pyyaml>=5.3.1, but you have pyyaml 5.3 which is incompatible.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "pandas-gbq 0.25.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-3.0.11 apache-beam-2.61.0 avro-python3-1.10.2 cloudpickle-2.2.1 colorama-0.4.6 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 google-auth-oauthlib-0.4.6 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 keras-2.8.0 keras-preprocessing-1.1.2 lvis-0.5.3 object_detection-0.1 objsize-0.7.0 portalocker-3.0.0 pyarrow-16.1.0 pyarrow-hotfix-0.6 pydot-1.4.2 pymongo-4.10.1 pyparsing-2.4.7 redis-5.2.1 sacrebleu-2.2.0 seqeval-1.2.2 sortedcontainers-2.4.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.8.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.8.2 tensorflow_io-0.37.1 tf-keras-2.15.0 tf-models-official-2.8.0 typeguard-2.13.3 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyparsing"
                ]
              },
              "id": "6746dffc4243436c85eead55eaffe6eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.65.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.1\n",
            "    Uninstalling tensorflow-2.8.1:\n",
            "      Successfully uninstalled tensorflow-2.8.1\n",
            "Successfully installed tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Collecting tensorflow_io==0.23.1\n",
            "  Downloading tensorflow_io-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.23.1 (from tensorflow_io==0.23.1)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
            "Downloading tensorflow_io-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow_io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorflow_io\n",
            "    Found existing installation: tensorflow-io 0.37.1\n",
            "    Uninstalling tensorflow-io-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-0.37.1\n",
            "Successfully installed tensorflow-io-gcs-filesystem-0.23.1 tensorflow_io-0.23.1\n",
            "--2024-12-20 14:48:23--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 190 [application/octet-stream]\n",
            "Saving to: ‘cuda-ubuntu1804.pin’\n",
            "\n",
            "cuda-ubuntu1804.pin 100%[===================>]     190  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-20 14:48:23 (4.97 MB/s) - ‘cuda-ubuntu1804.pin’ saved [190/190]\n",
            "\n",
            "--2024-12-20 14:48:23--  http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb [following]\n",
            "--2024-12-20 14:48:23--  https://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2273753684 (2.1G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb’\n",
            "\n",
            "cuda-repo-ubuntu180 100%[===================>]   2.12G  88.7MB/s    in 12s     \n",
            "\n",
            "2024-12-20 14:48:35 (181 MB/s) - ‘cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb’ saved [2273753684/2273753684]\n",
            "\n",
            "Selecting previously unselected package cuda-repo-ubuntu1804-11-0-local.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1804-11-0-local (11.0.2-450.51.05-1) ...\n",
            "Setting up cuda-repo-ubuntu1804-11-0-local (11.0.2-450.51.05-1) ...\n",
            "\n",
            "The public CUDA GPG key does not appear to be installed.\n",
            "To install the key, run this command:\n",
            "sudo apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
            "\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "Get:1 file:/var/cuda-repo-ubuntu1804-11-0-local  InRelease\n",
            "Ign:1 file:/var/cuda-repo-ubuntu1804-11-0-local  InRelease\n",
            "Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  Release [564 B]\n",
            "Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  Release [564 B]\n",
            "Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  Release.gpg [836 B]\n",
            "Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  Release.gpg [836 B]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 file:/var/cuda-repo-ubuntu1804-11-0-local  Packages [23.9 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,196 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,564 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,614 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,517 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,830 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,517 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Get:23 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.4 kB]\n",
            "Get:24 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,632 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,448 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Fetched 28.1 MB in 3s (9,871 kB/s)\n",
            "Reading package lists... Done\n",
            "W: file:/var/cuda-repo-ubuntu1804-11-0-local/Release.gpg: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n",
            "  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n",
            "  cuda-documentation-11-0 cuda-driver-dev-11-0 cuda-gdb-11-0\n",
            "  cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n",
            "  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n",
            "  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n",
            "  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n",
            "  cuda-nvvp-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-tools-11-0\n",
            "  cuda-visual-tools-11-0 default-jre default-jre-headless fonts-dejavu-core\n",
            "  fonts-dejavu-extra freeglut3 freeglut3-dev libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libcublas-11-0 libcublas-dev-11-0 libcufft-11-0\n",
            "  libcufft-dev-11-0 libcurand-11-0 libcurand-dev-11-0 libcusolver-11-0\n",
            "  libcusolver-dev-11-0 libcusparse-11-0 libcusparse-dev-11-0 libegl-dev\n",
            "  libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglu1-mesa\n",
            "  libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libice-dev\n",
            "  libnpp-11-0 libnpp-dev-11-0 libnvjpeg-11-0 libnvjpeg-dev-11-0 libopengl-dev\n",
            "  libsm-dev libxcb-cursor0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1\n",
            "  libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n",
            "  libxfixes-dev libxi-dev libxkbcommon-x11-0 libxkbfile1 libxmu-dev\n",
            "  libxmu-headers libxt-dev libxtst6 libxxf86dga1 nsight-systems-2024.5.1\n",
            "  openjdk-11-jre x11-utils\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n",
            "  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n",
            "  cuda-documentation-11-0 cuda-driver-dev-11-0 cuda-gdb-11-0\n",
            "  cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n",
            "  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n",
            "  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n",
            "  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n",
            "  cuda-nvvp-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-toolkit-11-0\n",
            "  cuda-tools-11-0 cuda-visual-tools-11-0 default-jre default-jre-headless\n",
            "  fonts-dejavu-core fonts-dejavu-extra freeglut3 freeglut3-dev\n",
            "  libatk-wrapper-java libatk-wrapper-java-jni libcublas-11-0\n",
            "  libcublas-dev-11-0 libcufft-11-0 libcufft-dev-11-0 libcurand-11-0\n",
            "  libcurand-dev-11-0 libcusolver-11-0 libcusolver-dev-11-0 libcusparse-11-0\n",
            "  libcusparse-dev-11-0 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev\n",
            "  libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libice-dev libnpp-11-0 libnpp-dev-11-0\n",
            "  libnvjpeg-11-0 libnvjpeg-dev-11-0 libopengl-dev libsm-dev libxcb-cursor0\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxfixes-dev libxi-dev\n",
            "  libxkbcommon-x11-0 libxkbfile1 libxmu-dev libxmu-headers libxt-dev libxtst6\n",
            "  libxxf86dga1 nsight-systems-2024.5.1 openjdk-11-jre x11-utils\n",
            "0 upgraded, 87 newly installed, 0 to remove and 54 not upgraded.\n",
            "Need to get 361 MB/1,943 MB of archives.\n",
            "After this operation, 4,022 MB of additional disk space will be used.\n",
            "Get:1 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cudart-11-0 11.0.194-1 [129 kB]\n",
            "Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-driver-dev-11-0 11.0.194-1 [25.0 kB]\n",
            "Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cudart-dev-11-0 11.0.194-1 [1,662 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2024.5.1 2024.5.1.113-245134619542v0 [356 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:6 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvcc-11-0 11.0.194-1 [21.1 MB]\n",
            "Get:7 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cupti-11-0 11.0.194-1 [10.5 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:10 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cupti-dev-11-0 11.0.194-1 [2,276 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [6,848 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmu-headers all 2:1.1.3-3 [54.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmu-dev amd64 2:1.1.3-3 [54.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfixes-dev amd64 1:6.0.0-1 [12.2 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxi-dev amd64 2:1.8-1build1 [193 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.25+9-1ubuntu1~22.04 [216 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libxcb-cursor0 amd64 0.1.1-4ubuntu1 [10.5 kB]\n",
            "Get:42 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvdisasm-11-0 11.0.194-1 [27.3 MB]\n",
            "Get:43 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cuobjdump-11-0 11.0.194-1 [103 kB]\n",
            "Get:44 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-gdb-11-0 11.0.194-1 [3,891 kB]\n",
            "Get:45 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-memcheck-11-0 11.0.194-1 [144 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:47 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvprof-11-0 11.0.194-1 [1,911 kB]\n",
            "Get:48 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvtx-11-0 11.0.167-1 [51.1 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:56 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-sanitizer-11-0 11.0.194-1 [7,220 kB]\n",
            "Get:57 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-command-line-tools-11-0 11.0.2-1 [2,474 B]\n",
            "Get:58 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvprune-11-0 11.0.167-1 [53.1 kB]\n",
            "Get:59 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-compiler-11-0 11.0.2-1 [2,416 B]\n",
            "Get:60 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvrtc-11-0 11.0.194-1 [6,521 kB]\n",
            "Get:61 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvrtc-dev-11-0 11.0.194-1 [22.1 kB]\n",
            "Get:62 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusolver-11-0 10.5.0.218-1 [277 MB]\n",
            "Get:63 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusolver-dev-11-0 10.5.0.218-1 [17.6 MB]\n",
            "Get:64 file:/var/cuda-repo-ubuntu1804-11-0-local  libcublas-11-0 11.1.0.229-1 [118 MB]\n",
            "Get:65 file:/var/cuda-repo-ubuntu1804-11-0-local  libcublas-dev-11-0 11.1.0.229-1 [120 MB]\n",
            "Get:66 file:/var/cuda-repo-ubuntu1804-11-0-local  libcufft-11-0 10.2.0.218-1 [94.1 MB]\n",
            "Get:67 file:/var/cuda-repo-ubuntu1804-11-0-local  libcufft-dev-11-0 10.2.0.218-1 [172 MB]\n",
            "Get:68 file:/var/cuda-repo-ubuntu1804-11-0-local  libcurand-11-0 10.2.1.218-1 [39.2 MB]\n",
            "Get:69 file:/var/cuda-repo-ubuntu1804-11-0-local  libcurand-dev-11-0 10.2.1.218-1 [39.2 MB]\n",
            "Get:70 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusparse-11-0 11.1.0.218-1 [71.2 MB]\n",
            "Get:71 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusparse-dev-11-0 11.1.0.218-1 [71.4 MB]\n",
            "Get:72 file:/var/cuda-repo-ubuntu1804-11-0-local  libnpp-11-0 11.1.0.218-1 [56.6 MB]\n",
            "Get:73 file:/var/cuda-repo-ubuntu1804-11-0-local  libnpp-dev-11-0 11.1.0.218-1 [57.4 MB]\n",
            "Get:74 file:/var/cuda-repo-ubuntu1804-11-0-local  libnvjpeg-11-0 11.1.0.218-1 [1,391 kB]\n",
            "Get:75 file:/var/cuda-repo-ubuntu1804-11-0-local  libnvjpeg-dev-11-0 11.1.0.218-1 [1,321 kB]\n",
            "Get:76 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-samples-11-0 11.0.194-1 [68.1 MB]\n",
            "Get:77 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-documentation-11-0 11.0.207-1 [59.6 MB]\n",
            "Get:78 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-libraries-11-0 11.0.2-1 [2,490 B]\n",
            "Get:79 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-libraries-dev-11-0 11.0.2-1 [2,514 B]\n",
            "Get:80 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-11-0 11.0.194-1 [119 MB]\n",
            "Get:81 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-compute-11-0 11.0.2-1 [3,718 B]\n",
            "Get:82 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-systems-11-0 11.0.2-1 [3,280 B]\n",
            "Get:83 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvml-dev-11-0 11.0.167-1 [71.9 kB]\n",
            "Get:84 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvvp-11-0 11.0.194-1 [115 MB]\n",
            "Get:85 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-visual-tools-11-0 11.0.2-1 [2,942 B]\n",
            "Get:86 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-tools-11-0 11.0.2-1 [2,380 B]\n",
            "Get:87 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-toolkit-11-0 11.0.2-1 [2,728 B]\n",
            "Fetched 361 MB in 16s (22.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 87.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cuda-cudart-11-0.\n",
            "(Reading database ... 123721 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-cudart-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-11-0.\n",
            "Preparing to unpack .../01-cuda-driver-dev-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-11-0.\n",
            "Preparing to unpack .../02-cuda-cudart-dev-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvcc-11-0.\n",
            "Preparing to unpack .../03-cuda-nvcc-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvcc-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-cupti-11-0.\n",
            "Preparing to unpack .../04-cuda-cupti-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-cupti-dev-11-0.\n",
            "Preparing to unpack .../05-cuda-cupti-dev-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-dev-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvdisasm-11-0.\n",
            "Preparing to unpack .../06-cuda-nvdisasm-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvdisasm-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-cuobjdump-11-0.\n",
            "Preparing to unpack .../07-cuda-cuobjdump-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cuobjdump-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-gdb-11-0.\n",
            "Preparing to unpack .../08-cuda-gdb-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-gdb-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-memcheck-11-0.\n",
            "Preparing to unpack .../09-cuda-memcheck-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-memcheck-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvprof-11-0.\n",
            "Preparing to unpack .../10-cuda-nvprof-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvprof-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvtx-11-0.\n",
            "Preparing to unpack .../11-cuda-nvtx-11-0_11.0.167-1_amd64.deb ...\n",
            "Unpacking cuda-nvtx-11-0 (11.0.167-1) ...\n",
            "Selecting previously unselected package cuda-sanitizer-11-0.\n",
            "Preparing to unpack .../12-cuda-sanitizer-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-sanitizer-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-11-0.\n",
            "Preparing to unpack .../13-cuda-command-line-tools-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-nvprune-11-0.\n",
            "Preparing to unpack .../14-cuda-nvprune-11-0_11.0.167-1_amd64.deb ...\n",
            "Unpacking cuda-nvprune-11-0 (11.0.167-1) ...\n",
            "Selecting previously unselected package cuda-compiler-11-0.\n",
            "Preparing to unpack .../15-cuda-compiler-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-compiler-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../16-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../17-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../18-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../19-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../20-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../21-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../22-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../23-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../24-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../25-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../26-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../27-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../28-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../29-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../30-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../31-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libxmu-headers.\n",
            "Preparing to unpack .../32-libxmu-headers_2%3a1.1.3-3_all.deb ...\n",
            "Unpacking libxmu-headers (2:1.1.3-3) ...\n",
            "Selecting previously unselected package libxmu-dev:amd64.\n",
            "Preparing to unpack .../33-libxmu-dev_2%3a1.1.3-3_amd64.deb ...\n",
            "Unpacking libxmu-dev:amd64 (2:1.1.3-3) ...\n",
            "Selecting previously unselected package libxfixes-dev:amd64.\n",
            "Preparing to unpack .../34-libxfixes-dev_1%3a6.0.0-1_amd64.deb ...\n",
            "Unpacking libxfixes-dev:amd64 (1:6.0.0-1) ...\n",
            "Selecting previously unselected package libxi-dev:amd64.\n",
            "Preparing to unpack .../35-libxi-dev_2%3a1.8-1build1_amd64.deb ...\n",
            "Unpacking libxi-dev:amd64 (2:1.8-1build1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-11-0.\n",
            "Preparing to unpack .../36-cuda-nvrtc-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-11-0.\n",
            "Preparing to unpack .../37-cuda-nvrtc-dev-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package libcusolver-11-0.\n",
            "Preparing to unpack .../38-libcusolver-11-0_10.5.0.218-1_amd64.deb ...\n",
            "Unpacking libcusolver-11-0 (10.5.0.218-1) ...\n",
            "Selecting previously unselected package libcusolver-dev-11-0.\n",
            "Preparing to unpack .../39-libcusolver-dev-11-0_10.5.0.218-1_amd64.deb ...\n",
            "Unpacking libcusolver-dev-11-0 (10.5.0.218-1) ...\n",
            "Selecting previously unselected package libcublas-11-0.\n",
            "Preparing to unpack .../40-libcublas-11-0_11.1.0.229-1_amd64.deb ...\n",
            "Unpacking libcublas-11-0 (11.1.0.229-1) ...\n",
            "Selecting previously unselected package libcublas-dev-11-0.\n",
            "Preparing to unpack .../41-libcublas-dev-11-0_11.1.0.229-1_amd64.deb ...\n",
            "Unpacking libcublas-dev-11-0 (11.1.0.229-1) ...\n",
            "Selecting previously unselected package libcufft-11-0.\n",
            "Preparing to unpack .../42-libcufft-11-0_10.2.0.218-1_amd64.deb ...\n",
            "Unpacking libcufft-11-0 (10.2.0.218-1) ...\n",
            "Selecting previously unselected package libcufft-dev-11-0.\n",
            "Preparing to unpack .../43-libcufft-dev-11-0_10.2.0.218-1_amd64.deb ...\n",
            "Unpacking libcufft-dev-11-0 (10.2.0.218-1) ...\n",
            "Selecting previously unselected package libcurand-11-0.\n",
            "Preparing to unpack .../44-libcurand-11-0_10.2.1.218-1_amd64.deb ...\n",
            "Unpacking libcurand-11-0 (10.2.1.218-1) ...\n",
            "Selecting previously unselected package libcurand-dev-11-0.\n",
            "Preparing to unpack .../45-libcurand-dev-11-0_10.2.1.218-1_amd64.deb ...\n",
            "Unpacking libcurand-dev-11-0 (10.2.1.218-1) ...\n",
            "Selecting previously unselected package libcusparse-11-0.\n",
            "Preparing to unpack .../46-libcusparse-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libcusparse-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libcusparse-dev-11-0.\n",
            "Preparing to unpack .../47-libcusparse-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libcusparse-dev-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libnpp-11-0.\n",
            "Preparing to unpack .../48-libnpp-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libnpp-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libnpp-dev-11-0.\n",
            "Preparing to unpack .../49-libnpp-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libnpp-dev-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libnvjpeg-11-0.\n",
            "Preparing to unpack .../50-libnvjpeg-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libnvjpeg-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libnvjpeg-dev-11-0.\n",
            "Preparing to unpack .../51-libnvjpeg-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libnvjpeg-dev-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package cuda-samples-11-0.\n",
            "Preparing to unpack .../52-cuda-samples-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-samples-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-documentation-11-0.\n",
            "Preparing to unpack .../53-cuda-documentation-11-0_11.0.207-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-11-0 (11.0.207-1) ...\n",
            "Selecting previously unselected package cuda-libraries-11-0.\n",
            "Preparing to unpack .../54-cuda-libraries-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-11-0.\n",
            "Preparing to unpack .../55-cuda-libraries-dev-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package default-jre-headless.\n",
            "Preparing to unpack .../56-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jre-headless (2:1.11-72build2) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../57-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-11-jre:amd64.\n",
            "Preparing to unpack .../58-openjdk-11-jre_11.0.25+9-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jre:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package default-jre.\n",
            "Preparing to unpack .../59-default-jre_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jre (2:1.11-72build2) ...\n",
            "Selecting previously unselected package cuda-nsight-11-0.\n",
            "Preparing to unpack .../60-cuda-nsight-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nsight-compute-11-0.\n",
            "Preparing to unpack .../61-cuda-nsight-compute-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-compute-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../62-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../63-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../64-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../65-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../66-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../67-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../68-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../69-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../70-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-cursor0:amd64.\n",
            "Preparing to unpack .../71-libxcb-cursor0_0.1.1-4ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-cursor0:amd64 (0.1.1-4ubuntu1) ...\n",
            "Selecting previously unselected package nsight-systems-2024.5.1.\n",
            "Preparing to unpack .../72-nsight-systems-2024.5.1_2024.5.1.113-245134619542v0_amd64.deb ...\n",
            "Unpacking nsight-systems-2024.5.1 (2024.5.1.113-245134619542v0) ...\n",
            "Selecting previously unselected package cuda-nsight-systems-11-0.\n",
            "Preparing to unpack .../73-cuda-nsight-systems-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-systems-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-11-0.\n",
            "Preparing to unpack .../74-cuda-nvml-dev-11-0_11.0.167-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-11-0 (11.0.167-1) ...\n",
            "Selecting previously unselected package cuda-nvvp-11-0.\n",
            "Preparing to unpack .../75-cuda-nvvp-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvvp-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-11-0.\n",
            "Preparing to unpack .../76-cuda-visual-tools-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-tools-11-0.\n",
            "Preparing to unpack .../77-cuda-tools-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-tools-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-11-0.\n",
            "Preparing to unpack .../78-cuda-toolkit-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../79-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../80-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../81-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../82-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../83-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../84-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../85-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../86-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up libcurand-11-0 (10.2.1.218-1) ...\n",
            "Setting up libcublas-11-0 (11.1.0.229-1) ...\n",
            "Setting up libxmu-headers (2:1.1.3-3) ...\n",
            "Setting up cuda-nvtx-11-0 (11.0.167-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up default-jre-headless (2:1.11-72build2) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libcusolver-11-0 (10.5.0.218-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up cuda-driver-dev-11-0 (11.0.194-1) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up cuda-nsight-compute-11-0 (11.0.2-1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up cuda-memcheck-11-0 (11.0.194-1) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up openjdk-11-jre:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up default-jre (2:1.11-72build2) ...\n",
            "Setting up cuda-nvprune-11-0 (11.0.167-1) ...\n",
            "Setting up libnvjpeg-11-0 (11.1.0.218-1) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up cuda-cudart-11-0 (11.0.194-1) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxfixes-dev:amd64 (1:6.0.0-1) ...\n",
            "Setting up cuda-nvprof-11-0 (11.0.194-1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up cuda-nvml-dev-11-0 (11.0.167-1) ...\n",
            "Setting up libxcb-cursor0:amd64 (0.1.1-4ubuntu1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libcusparse-11-0 (11.1.0.218-1) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up cuda-cuobjdump-11-0 (11.0.194-1) ...\n",
            "Setting up libcufft-11-0 (10.2.0.218-1) ...\n",
            "Setting up cuda-cudart-dev-11-0 (11.0.194-1) ...\n",
            "Setting up cuda-nvrtc-11-0 (11.0.194-1) ...\n",
            "Setting up cuda-sanitizer-11-0 (11.0.194-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libcufft-dev-11-0 (10.2.0.218-1) ...\n",
            "Setting up libnpp-11-0 (11.1.0.218-1) ...\n",
            "Setting up libcusolver-dev-11-0 (10.5.0.218-1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up cuda-nvdisasm-11-0 (11.0.194-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxi-dev:amd64 (2:1.8-1build1) ...\n",
            "Setting up libcublas-dev-11-0 (11.1.0.229-1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libcusparse-dev-11-0 (11.1.0.218-1) ...\n",
            "Setting up cuda-nvvp-11-0 (11.0.194-1) ...\n",
            "Setting up libcurand-dev-11-0 (10.2.1.218-1) ...\n",
            "Setting up libnpp-dev-11-0 (11.1.0.218-1) ...\n",
            "Setting up cuda-libraries-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-gdb-11-0 (11.0.194-1) ...\n",
            "Setting up cuda-nvrtc-dev-11-0 (11.0.194-1) ...\n",
            "Setting up nsight-systems-2024.5.1 (2024.5.1.113-245134619542v0) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2024.5.1/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2024.5.1/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up cuda-nsight-11-0 (11.0.194-1) ...\n",
            "Setting up libnvjpeg-dev-11-0 (11.1.0.218-1) ...\n",
            "Setting up libxmu-dev:amd64 (2:1.1.3-3) ...\n",
            "Setting up cuda-nvcc-11-0 (11.0.194-1) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up cuda-libraries-dev-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-cupti-11-0 (11.0.194-1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up cuda-nsight-systems-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-visual-tools-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-compiler-11-0 (11.0.2-1) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up cuda-cupti-dev-11-0 (11.0.194-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up cuda-command-line-tools-11-0 (11.0.2-1) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Setting up cuda-tools-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-samples-11-0 (11.0.194-1) ...\n",
            "Setting up cuda-documentation-11-0 (11.0.207-1) ...\n",
            "Setting up cuda-toolkit-11-0 (11.0.2-1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "# Install the Object Detection API (NOTE: This block takes about 10 minutes to finish executing)\n",
        "\n",
        "# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n",
        "!pip install pyyaml==5.3\n",
        "!pip install /content/models/research/\n",
        "\n",
        "# Need to downgrade to TF v2.8.0 due to Colab compatibility bug with TF v2.10 (as of 10/03/22)\n",
        "!pip install tensorflow==2.8.0\n",
        "\n",
        "# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n",
        "!pip install tensorflow_io==0.23.1\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
        "!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
        "!apt-get update && sudo apt-get install cuda-toolkit-11-0\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V7TrfUos-9E"
      },
      "source": [
        "You may get warnings or errors related to package dependencies in the previous code block, but you can ignore them for now.\n",
        "\n",
        "Let's test our installation by running `model_builder_tf2_test.py` to make sure everything is working as expected. Run the following code block and confirm that it finishes without errors. If you get errors, try Googling them or checking the FAQ at the end of this Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wh_HPMOqWH9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bc6cf3-c2a6-4f4b-fd33-d217288ac442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2024-12-20 15:09:44.352150: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W1220 15:09:44.611784 133699186815616 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.27s\n",
            "I1220 15:09:44.983149 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.27s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.48s\n",
            "I1220 15:09:45.463784 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.48s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "I1220 15:09:45.716364 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
            "I1220 15:09:45.941031 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.79s\n",
            "I1220 15:09:47.730446 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.79s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1220 15:09:47.731627 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I1220 15:09:47.753890 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I1220 15:09:47.767053 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I1220 15:09:47.780384 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I1220 15:09:47.871843 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "I1220 15:09:47.953124 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I1220 15:09:48.042277 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
            "I1220 15:09:48.126893 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
            "I1220 15:09:48.208539 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I1220 15:09:48.234229 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1220 15:09:48.390919 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1220 15:09:48.391073 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I1220 15:09:48.391161 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I1220 15:09:48.396416 133699186815616 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:09:48.412654 133699186815616 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:09:48.412761 133699186815616 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:09:48.480262 133699186815616 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:09:48.480379 133699186815616 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:09:48.635178 133699186815616 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:09:48.635312 133699186815616 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1220 15:09:48.812862 133699186815616 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1220 15:09:48.813003 133699186815616 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1220 15:09:49.019855 133699186815616 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1220 15:09:49.020002 133699186815616 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1220 15:09:49.234344 133699186815616 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1220 15:09:49.234523 133699186815616 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1220 15:09:49.549165 133699186815616 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1220 15:09:49.549315 133699186815616 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I1220 15:09:49.618030 133699186815616 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I1220 15:09:49.655508 133699186815616 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:09:49.701697 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1220 15:09:49.701846 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I1220 15:09:49.701928 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I1220 15:09:49.703917 133699186815616 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:09:49.718313 133699186815616 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:09:49.718429 133699186815616 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:09:49.831001 133699186815616 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:09:49.831110 133699186815616 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:09:50.147093 133699186815616 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:09:50.147271 133699186815616 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1220 15:09:50.438205 133699186815616 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1220 15:09:50.438393 133699186815616 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1220 15:09:51.048720 133699186815616 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1220 15:09:51.048906 133699186815616 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1220 15:09:51.468790 133699186815616 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1220 15:09:51.468978 133699186815616 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1220 15:09:51.999756 133699186815616 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1220 15:09:51.999941 133699186815616 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I1220 15:09:52.194285 133699186815616 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I1220 15:09:52.232316 133699186815616 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:09:52.328682 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1220 15:09:52.328858 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I1220 15:09:52.328934 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I1220 15:09:52.331255 133699186815616 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:09:52.351372 133699186815616 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:09:52.351536 133699186815616 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:09:52.505774 133699186815616 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:09:52.505942 133699186815616 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:09:52.822591 133699186815616 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:09:52.822949 133699186815616 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1220 15:09:53.090812 133699186815616 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1220 15:09:53.090969 133699186815616 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I1220 15:09:53.370459 133699186815616 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I1220 15:09:53.370615 133699186815616 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I1220 15:09:53.659457 133699186815616 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I1220 15:09:53.659608 133699186815616 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I1220 15:09:54.029506 133699186815616 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I1220 15:09:54.029661 133699186815616 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I1220 15:09:54.174219 133699186815616 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I1220 15:09:54.204549 133699186815616 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:09:54.264917 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1220 15:09:54.265061 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I1220 15:09:54.265134 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I1220 15:09:54.266609 133699186815616 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I1220 15:09:54.280285 133699186815616 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I1220 15:09:54.280390 133699186815616 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:09:54.392318 133699186815616 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:09:54.392461 133699186815616 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1220 15:09:54.605794 133699186815616 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1220 15:09:54.605913 133699186815616 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1220 15:09:54.819117 133699186815616 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1220 15:09:54.819266 133699186815616 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I1220 15:09:55.182901 133699186815616 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I1220 15:09:55.183058 133699186815616 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I1220 15:09:55.536458 133699186815616 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I1220 15:09:55.536598 133699186815616 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I1220 15:09:55.968067 133699186815616 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I1220 15:09:55.968216 133699186815616 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I1220 15:09:56.107139 133699186815616 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I1220 15:09:56.134952 133699186815616 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:09:56.426563 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1220 15:09:56.426713 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I1220 15:09:56.426785 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1220 15:09:56.428227 133699186815616 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1220 15:09:56.442898 133699186815616 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1220 15:09:56.443016 133699186815616 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:09:56.568220 133699186815616 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:09:56.568341 133699186815616 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1220 15:09:56.850616 133699186815616 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1220 15:09:56.850758 133699186815616 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I1220 15:09:57.143487 133699186815616 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I1220 15:09:57.143660 133699186815616 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I1220 15:09:57.583734 133699186815616 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I1220 15:09:57.583890 133699186815616 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I1220 15:09:58.012662 133699186815616 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I1220 15:09:58.012822 133699186815616 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I1220 15:09:58.576510 133699186815616 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I1220 15:09:58.576704 133699186815616 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I1220 15:09:58.716168 133699186815616 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I1220 15:09:58.742311 133699186815616 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:09:58.814856 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1220 15:09:58.814974 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I1220 15:09:58.815040 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1220 15:09:58.816486 133699186815616 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1220 15:09:58.831217 133699186815616 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1220 15:09:58.831317 133699186815616 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:09:59.003583 133699186815616 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:09:59.003725 133699186815616 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1220 15:09:59.357546 133699186815616 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1220 15:09:59.357699 133699186815616 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I1220 15:09:59.709376 133699186815616 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I1220 15:09:59.709541 133699186815616 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I1220 15:10:00.215205 133699186815616 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I1220 15:10:00.215356 133699186815616 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I1220 15:10:00.710839 133699186815616 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I1220 15:10:00.711000 133699186815616 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I1220 15:10:01.361383 133699186815616 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I1220 15:10:01.361555 133699186815616 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I1220 15:10:01.574460 133699186815616 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I1220 15:10:01.601647 133699186815616 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:01.967018 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1220 15:10:01.967177 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1220 15:10:01.967243 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1220 15:10:01.968818 133699186815616 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I1220 15:10:01.983773 133699186815616 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I1220 15:10:01.983884 133699186815616 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1220 15:10:02.164881 133699186815616 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1220 15:10:02.165027 133699186815616 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1220 15:10:02.602816 133699186815616 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1220 15:10:02.602980 133699186815616 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I1220 15:10:03.063049 133699186815616 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I1220 15:10:03.065065 133699186815616 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I1220 15:10:03.841351 133699186815616 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I1220 15:10:03.841573 133699186815616 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I1220 15:10:04.614821 133699186815616 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I1220 15:10:04.615012 133699186815616 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I1220 15:10:05.753610 133699186815616 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I1220 15:10:05.753810 133699186815616 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I1220 15:10:06.060664 133699186815616 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I1220 15:10:06.093065 133699186815616 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:06.194473 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1220 15:10:06.194636 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1220 15:10:06.194719 133699186815616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1220 15:10:06.196208 133699186815616 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I1220 15:10:06.211098 133699186815616 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I1220 15:10:06.211199 133699186815616 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1220 15:10:06.438633 133699186815616 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1220 15:10:06.438768 133699186815616 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I1220 15:10:06.936239 133699186815616 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I1220 15:10:06.936413 133699186815616 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I1220 15:10:07.435959 133699186815616 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I1220 15:10:07.436115 133699186815616 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I1220 15:10:08.148563 133699186815616 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I1220 15:10:08.148727 133699186815616 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I1220 15:10:09.216143 133699186815616 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I1220 15:10:09.216300 133699186815616 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I1220 15:10:10.163121 133699186815616 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I1220 15:10:10.163280 133699186815616 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I1220 15:10:10.453724 133699186815616 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I1220 15:10:10.495390 133699186815616 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.37s\n",
            "I1220 15:10:10.609461 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.37s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I1220 15:10:10.621948 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1220 15:10:10.623514 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1220 15:10:10.623987 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1220 15:10:10.625378 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1220 15:10:10.626710 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1220 15:10:10.627123 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1220 15:10:10.628078 133699186815616 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 26.916s\n",
            "\n",
            "OK (skipped=1)\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2024-12-20 15:10:15.671852: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W1220 15:10:15.888776 140195158188672 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.34s\n",
            "I1220 15:10:16.364488 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.34s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.76s\n",
            "I1220 15:10:17.129473 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.76s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.4s\n",
            "I1220 15:10:17.525712 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.4s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.37s\n",
            "I1220 15:10:17.893018 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.37s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.16s\n",
            "I1220 15:10:20.048858 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1220 15:10:20.050036 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I1220 15:10:20.072038 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I1220 15:10:20.085226 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I1220 15:10:20.098595 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I1220 15:10:20.186817 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "I1220 15:10:20.269299 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I1220 15:10:20.361787 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
            "I1220 15:10:20.445812 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
            "I1220 15:10:20.529967 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "I1220 15:10:20.554603 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1220 15:10:20.725363 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1220 15:10:20.725517 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I1220 15:10:20.725589 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I1220 15:10:20.727704 140195158188672 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:10:20.743462 140195158188672 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:10:20.743568 140195158188672 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:10:20.798171 140195158188672 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:10:20.798276 140195158188672 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:10:20.936498 140195158188672 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:10:20.936603 140195158188672 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1220 15:10:21.079330 140195158188672 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1220 15:10:21.079454 140195158188672 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1220 15:10:21.290480 140195158188672 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1220 15:10:21.290595 140195158188672 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1220 15:10:21.498435 140195158188672 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1220 15:10:21.498555 140195158188672 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1220 15:10:21.792796 140195158188672 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1220 15:10:21.792948 140195158188672 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I1220 15:10:21.858332 140195158188672 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I1220 15:10:21.890226 140195158188672 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:21.934885 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1220 15:10:21.935000 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I1220 15:10:21.935071 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I1220 15:10:21.936494 140195158188672 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:10:21.949989 140195158188672 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:10:21.950088 140195158188672 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:10:22.058572 140195158188672 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:10:22.058681 140195158188672 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:10:22.269246 140195158188672 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:10:22.269367 140195158188672 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1220 15:10:22.476054 140195158188672 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1220 15:10:22.476170 140195158188672 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1220 15:10:22.956851 140195158188672 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1220 15:10:22.957011 140195158188672 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1220 15:10:23.236555 140195158188672 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1220 15:10:23.236702 140195158188672 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1220 15:10:23.591218 140195158188672 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1220 15:10:23.591373 140195158188672 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I1220 15:10:23.735772 140195158188672 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I1220 15:10:23.762736 140195158188672 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:23.817095 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1220 15:10:23.817215 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I1220 15:10:23.817286 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I1220 15:10:23.818696 140195158188672 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:10:23.832312 140195158188672 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1220 15:10:23.832430 140195158188672 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:10:23.946343 140195158188672 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1220 15:10:23.946470 140195158188672 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:10:24.151708 140195158188672 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1220 15:10:24.151825 140195158188672 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1220 15:10:24.363672 140195158188672 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1220 15:10:24.363800 140195158188672 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I1220 15:10:24.643809 140195158188672 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I1220 15:10:24.643972 140195158188672 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I1220 15:10:24.940081 140195158188672 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I1220 15:10:24.940266 140195158188672 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I1220 15:10:25.290750 140195158188672 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I1220 15:10:25.290945 140195158188672 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I1220 15:10:25.429643 140195158188672 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I1220 15:10:25.457015 140195158188672 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:25.518862 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1220 15:10:25.519047 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I1220 15:10:25.519151 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I1220 15:10:25.521021 140195158188672 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I1220 15:10:25.536314 140195158188672 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I1220 15:10:25.536437 140195158188672 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:10:25.645205 140195158188672 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:10:25.645338 140195158188672 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1220 15:10:25.865611 140195158188672 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1220 15:10:25.865778 140195158188672 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1220 15:10:26.070957 140195158188672 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1220 15:10:26.071101 140195158188672 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I1220 15:10:26.426417 140195158188672 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I1220 15:10:26.426589 140195158188672 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I1220 15:10:26.783597 140195158188672 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I1220 15:10:26.783759 140195158188672 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I1220 15:10:27.232905 140195158188672 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I1220 15:10:27.233077 140195158188672 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I1220 15:10:27.371160 140195158188672 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I1220 15:10:27.399358 140195158188672 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:27.697269 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1220 15:10:27.697446 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I1220 15:10:27.697523 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1220 15:10:27.699018 140195158188672 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1220 15:10:27.714104 140195158188672 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1220 15:10:27.714222 140195158188672 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:10:27.826151 140195158188672 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:10:27.826326 140195158188672 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1220 15:10:28.124717 140195158188672 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1220 15:10:28.124896 140195158188672 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I1220 15:10:28.407679 140195158188672 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I1220 15:10:28.407863 140195158188672 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I1220 15:10:28.842519 140195158188672 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I1220 15:10:28.842674 140195158188672 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I1220 15:10:29.287894 140195158188672 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I1220 15:10:29.288060 140195158188672 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I1220 15:10:30.082916 140195158188672 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I1220 15:10:30.083103 140195158188672 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I1220 15:10:30.266707 140195158188672 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I1220 15:10:30.299792 140195158188672 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:30.407510 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1220 15:10:30.407658 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I1220 15:10:30.407733 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1220 15:10:30.409742 140195158188672 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1220 15:10:30.428680 140195158188672 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1220 15:10:30.428801 140195158188672 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:10:30.642735 140195158188672 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1220 15:10:30.642881 140195158188672 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1220 15:10:31.157349 140195158188672 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1220 15:10:31.157557 140195158188672 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I1220 15:10:31.660001 140195158188672 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I1220 15:10:31.660196 140195158188672 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I1220 15:10:32.365035 140195158188672 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I1220 15:10:32.365229 140195158188672 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I1220 15:10:32.905091 140195158188672 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I1220 15:10:32.905256 140195158188672 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I1220 15:10:33.546158 140195158188672 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I1220 15:10:33.546320 140195158188672 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I1220 15:10:33.756980 140195158188672 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I1220 15:10:33.785185 140195158188672 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:34.142438 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1220 15:10:34.142590 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1220 15:10:34.142666 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1220 15:10:34.144148 140195158188672 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I1220 15:10:34.159507 140195158188672 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I1220 15:10:34.159620 140195158188672 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1220 15:10:34.330270 140195158188672 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1220 15:10:34.330409 140195158188672 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1220 15:10:34.759712 140195158188672 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1220 15:10:34.759860 140195158188672 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I1220 15:10:35.190045 140195158188672 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I1220 15:10:35.190195 140195158188672 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I1220 15:10:35.754255 140195158188672 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I1220 15:10:35.754431 140195158188672 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I1220 15:10:36.324877 140195158188672 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I1220 15:10:36.325046 140195158188672 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I1220 15:10:37.088880 140195158188672 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I1220 15:10:37.089044 140195158188672 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I1220 15:10:37.298454 140195158188672 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I1220 15:10:37.323917 140195158188672 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1220 15:10:37.418318 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1220 15:10:37.418478 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1220 15:10:37.418553 140195158188672 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1220 15:10:37.420000 140195158188672 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I1220 15:10:37.433805 140195158188672 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I1220 15:10:37.433915 140195158188672 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1220 15:10:37.660928 140195158188672 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1220 15:10:37.661059 140195158188672 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I1220 15:10:38.152038 140195158188672 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I1220 15:10:38.152197 140195158188672 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I1220 15:10:38.653933 140195158188672 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I1220 15:10:38.654098 140195158188672 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I1220 15:10:39.368866 140195158188672 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I1220 15:10:39.369033 140195158188672 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I1220 15:10:40.397537 140195158188672 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I1220 15:10:40.397723 140195158188672 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I1220 15:10:41.325621 140195158188672 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I1220 15:10:41.325776 140195158188672 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I1220 15:10:41.604672 140195158188672 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I1220 15:10:41.640823 140195158188672 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.2s\n",
            "I1220 15:10:41.750529 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.2s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1220 15:10:41.762237 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1220 15:10:41.763859 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1220 15:10:41.764339 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1220 15:10:41.765779 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1220 15:10:41.767050 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1220 15:10:41.767514 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1220 15:10:41.768639 140195158188672 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 26.745s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "# Downgrade protobuf to a compatible version\n",
        "# Update the protobuf library to a compatible version\n",
        "!pip install protobuf==3.20.*\n",
        "\n",
        "\n",
        "# Verify the installation\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n",
        "\n",
        "# Run Model Bulider Test file, just to verify everything's working properly\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.&nbsp;Upload Image Dataset and Prepare Training Data"
      ],
      "metadata": {
        "id": "eydREUsMGUUR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZVCxE4nSVI"
      },
      "source": [
        "In this section, we'll upload our data and prepare it for training with TensorFlow. We'll upload our images, split them into train, validation, and test folders, and then run scripts for creating TFRecords from our data.\n",
        "\n",
        "First, on your local PC, zip all your training images and XML files into a single folder called \"images.zip\". The files should be directly inside the zip folder, or in a nested folder as shown below:\n",
        "```\n",
        "images.zip\n",
        "-- images\n",
        "  -- img1.jpg\n",
        "  -- img1.xml\n",
        "  -- img2.jpg\n",
        "  -- img2.xml\n",
        "  ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Upload images\n",
        "There are three options for moving the image files to this Colab instance."
      ],
      "metadata": {
        "id": "LE1MtX4HGQA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 1. Upload through Google Colab**\n",
        "\n",
        "Upload the \"images.zip\" file to the Google Colab instance by clicking the \"Files\" icon on the left hand side of the browser, and then the \"Upload to session storage\" icon. Select the zip folder to upload it.\n",
        "\n",
        "![](https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/doc/colab_upload_button.png)"
      ],
      "metadata": {
        "id": "sFSJoDEnJotN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 2. Copy from Google Drive**\n",
        "\n",
        "You can also upload your images to your personal Google Drive, mount the drive on this Colab session, and copy them over to the Colab filesystem. This option works well if you want to upload the images beforehand so you don't have to wait for them to upload each time you restart this Colab. If you have more than 50MB worth of images, I recommend using this option.\n",
        "\n",
        "First, upload the \"images.zip\" file to your Google Drive, and make note of the folder you uploaded them to. Replace `MyDrive/path/to/images.zip` with the path to your zip file. (For example, I uploaded the zip file to folder called \"change-counter1\", so I would use `MyDrive/change-counter1/images.zip` for the path). Then, run the following block of code to mount your Google Drive to this Colab session and copy the folder to this filesystem."
      ],
      "metadata": {
        "id": "hGsPlloAGIXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tLgAPsQsfTLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ae8335-b03e-421b-bbec-3ef15acd9844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "cp: cannot stat '/content/gdrive/MyDrive/path/to/images.zip': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/MyDrive/path/to/images.zip /content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 3. Use coin detection dataset**\n",
        "\n",
        "If you don't have a dataset and just want to try training a model, you can download my coin image dataset to use as an example. I've uploaded a dataset containing 750 labeled images of pennies, nickels, dimes, and quarters. Run the following code block to download the dataset."
      ],
      "metadata": {
        "id": "9xAJMKwpFilm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHjOhoSGYwT7"
      },
      "source": [
        "## 3.2 Split images into train, validation, and test folders\n",
        "At this point, whether you used Option 1, 2, or 3, you should be able to click the folder icon on the left and see your \"images.zip\" file in the list of files. Now that the dataset is uploaded, let's unzip it and create some folders to hold the images. These directories are created in the /content folder in this instance's filesystem. You can browse the filesystem by clicking the \"Files\" icon on the left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mGvoHH-unSVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b239f4ab-8146-48e6-f623-3f854954a733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/images’: File exists\n",
            "[images.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of images.zip or\n",
            "        images.zip.zip, and cannot find images.zip.ZIP, period.\n",
            "mkdir: cannot create directory ‘/content/images/train’: File exists\n",
            "mkdir: cannot create directory ‘/content/images/validation’: File exists\n",
            "mkdir: cannot create directory ‘/content/images/test’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/images\n",
        "!unzip -q images.zip -d /content/images/all\n",
        "!mkdir /content/images/train; mkdir /content/images/validation; mkdir /content/images/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-6RIcrwbQMh"
      },
      "source": [
        "Next, we'll split the images into train, validation, and test sets. Here's what each set is used for:\n",
        "\n",
        "\n",
        "\n",
        "*   **Train**: These are the actual images used to train the model. In each step of training, a batch of images from the \"train\" set is passed into the neural network. The network predicts classes and locations of objects in the images. The training algorithm calculates the loss (i.e. how \"wrong\" the predictions were) and adjusts the network weights through backpropagation.\n",
        "\n",
        "\n",
        "*   **Validation**: Images from the \"validation\" set can be used by the training algorithm to check the progress of training and adjust hyperparameters (like learning rate). Unlike \"train\" images, these images are only used periodically during training (i.e. once every certain number of training steps).\n",
        "\n",
        "\n",
        "* **Test**: These images are never seen by the neural network during training. They are intended to be used by a human to perform final testing of the model to check how accurate the model is.\n",
        "\n",
        "I wrote a Python script to randomly move 80% of the images to the \"train\" folder, 10% to the \"validation\" folder, and 10% to the \"test\" folder. Click play on the following block to download the script and execute it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/train_val_test_split.py\n",
        "!python train_val_test_split.py"
      ],
      "metadata": {
        "id": "PfuZpmdBLjh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84338197-a51b-4c13-b741-6c677ae3ffae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-20 15:52:28--  https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/train_val_test_split.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3100 (3.0K) [text/plain]\n",
            "Saving to: ‘train_val_test_split.py.2’\n",
            "\n",
            "\r          train_val   0%[                    ]       0  --.-KB/s               \rtrain_val_test_spli 100%[===================>]   3.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-20 15:52:28 (47.1 MB/s) - ‘train_val_test_split.py.2’ saved [3100/3100]\n",
            "\n",
            "Total images: 750\n",
            "Images moving to train: 600\n",
            "Images moving to validation: 75\n",
            "Images moving to test: 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p--K1PJXEgNo"
      },
      "source": [
        "## 3.3 Create Labelmap and TFRecords\n",
        "Finally, we need to create a labelmap for the detector and convert the images into a data file format called TFRecords, which are used by TensorFlow for training. We'll use Python scripts to automatically convert the data into TFRecord format. Before running them, we need to define a labelmap for our classes.\n",
        "\n",
        "The code section below will create a \"labelmap.txt\" file that contains a list of classes. Replace the `class1`, `class2`, `class3` text with your own classes (for example, `penny`, `nickel`, `dime`, `quarter`), adding a new line for each class. Then, click play to execute the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_DE_r4MKY7ln"
      },
      "outputs": [],
      "source": [
        "### This creates a a \"labelmap.txt\" file with a list of classes the object detection model will detect.\n",
        "%%bash\n",
        "cat <<EOF >> /content/labelmap.txt\n",
        "class1\n",
        "class2\n",
        "class3\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pa2VYhTIT1l"
      },
      "source": [
        "Download and run the data conversion scripts from the [GitHub repository](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi) by clicking play on the following three sections of code. They will create TFRecord files for the train and validation datasets, as well as a `labelmap.pbtxt` file which contains the labelmap in a different format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data conversion scripts\n",
        "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_csv.py\n",
        "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py"
      ],
      "metadata": {
        "id": "laZZE0TlEeUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b70991-72e2-4b26-fb55-25b2d904be28"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-20 15:21:04--  https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_csv.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1348 (1.3K) [text/plain]\n",
            "Saving to: ‘create_csv.py.1’\n",
            "\n",
            "create_csv.py.1     100%[===================>]   1.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-20 15:21:04 (88.3 MB/s) - ‘create_csv.py.1’ saved [1348/1348]\n",
            "\n",
            "--2024-12-20 15:21:04--  https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4414 (4.3K) [text/plain]\n",
            "Saving to: ‘create_tfrecord.py.1’\n",
            "\n",
            "create_tfrecord.py. 100%[===================>]   4.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-20 15:21:04 (75.7 MB/s) - ‘create_tfrecord.py.1’ saved [4414/4414]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5tdDbTmHYwu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc90fcb-551a-4bd1-ee08-a3993c55db4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/create_tfrecord.py\", line 120, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/create_tfrecord.py\", line 98, in main\n",
            "    tf_example = create_tf_example(group, path)\n",
            "  File \"/content/create_tfrecord.py\", line 70, in create_tf_example\n",
            "    classes.append(int(labels.index(row['class'])+1))\n",
            "ValueError: 'nickel' is not in list\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/create_tfrecord.py\", line 120, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/create_tfrecord.py\", line 98, in main\n",
            "    tf_example = create_tf_example(group, path)\n",
            "  File \"/content/create_tfrecord.py\", line 70, in create_tf_example\n",
            "    classes.append(int(labels.index(row['class'])+1))\n",
            "ValueError: 'penny' is not in list\n"
          ]
        }
      ],
      "source": [
        "# Create CSV data files and TFRecord files\n",
        "!python3 create_csv.py\n",
        "!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord\n",
        "!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNyv_YyDXwMs"
      },
      "source": [
        "We'll store the locations of the TFRecord and labelmap files as variables so we can reference them later in this Colab session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YUd2wtfrqedy"
      },
      "outputs": [],
      "source": [
        "train_record_fname = '/content/train.tfrecord'\n",
        "val_record_fname = '/content/val.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/labelmap.pbtxt'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.&nbsp;Set Up Training Configuration"
      ],
      "metadata": {
        "id": "eGEUZYAMEZ6f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "In this section, we'll set up the model and training configuration. We'll specifiy which pretrained TensorFlow model we want to use from the [TensorFlow 2 Object Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Each model also comes with a configuration file that points to file locations, sets training parameters (such as learning rate and total number of training steps), and more. We'll modify the configuration file for our custom training job.\n",
        "\n",
        "The first section of code lists out some models availabe in the TF2 Model Zoo and defines some filenames that will be used later to download the model and config file. This makes it easy to manage which model you're using and to add other models to the list later.\n",
        "\n",
        "Set the \"chosen_model\" variable to match the name of the model you'd like to train with. It's currently set to use the popular \"ssd-mobilenet-v2\" model. Click play on the next block once the chosen model has been set.\n",
        "\n",
        "Not sure which model to pick? [Check out my blog post comparing each model's speed and accuracy.](https://ejtech.io/learn/tflite-object-detection-model-comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN0EUEa3e5Un"
      },
      "outputs": [],
      "source": [
        "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
        "chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "    },\n",
        "    'ssd-mobilenet-v2-fpnlite-320': {\n",
        "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "    # The centernet model isn't working as of 9/10/22\n",
        "    #'centernet-mobilenet-v2': {\n",
        "    #    'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n",
        "    #    'base_pipeline_file': 'pipeline.config',\n",
        "    #    'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n",
        "    #}\n",
        "}\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the pretrained model file and configuration file by clicking Play on the following section."
      ],
      "metadata": {
        "id": "JMG3EEPqPggV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG4TmJUVrYQ7"
      },
      "outputs": [],
      "source": [
        "# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n",
        "%mkdir /content/models/mymodel/\n",
        "%cd /content/models/mymodel/\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFAlqNrPn5y3"
      },
      "source": [
        "Now that we've downloaded our model and config file, we need to modify the configuration file with some high-level training parameters. The following variables are used to control training steps:\n",
        "\n",
        "* **num_steps**: The total amount of steps to use for training the model. A good number to start with is 40,000 steps. You can use more steps if you notice the loss metrics are still decreasing by the time training finishes. The more steps, the longer training will take. Training can also be stopped early if loss flattens out before reaching the specified number of steps.\n",
        "* **batch_size**: The number of images to use per training step. A larger batch size allows a model to be trained in fewer steps, but the size is limited by the GPU memory available for training. With the GPUs used in Colab instances, 16 is a good number for SSD models and 4 is good for EfficientDet models.\n",
        "\n",
        "Other training information, like the location of the pretrained model file, the config file, and total number of classes are also assigned in this step. To learn more about training configuration with the TensorFlow Object Detection API, read this [article from Neptune](https://neptune.ai/blog/tensorflow-object-detection-api-best-practices-to-training-evaluation-deployment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lYDvJN-n69v"
      },
      "outputs": [],
      "source": [
        "# Set training parameters for the model\n",
        "num_steps = 40000\n",
        "\n",
        "if chosen_model == 'efficientdet-d0':\n",
        "  batch_size = 4\n",
        "else:\n",
        "  batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_ki9jOqxn7V"
      },
      "outputs": [],
      "source": [
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "print('Total classes:', num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwPyaIAXxyKu"
      },
      "source": [
        "Next, we'll rewrite the config file to use the training parameters we just specified. The following section of code will automatically replace the necessary parameters in the downloaded .config file and save it as our custom \"pipeline_file.config\" file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eA5ht3_yukT"
      },
      "outputs": [],
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "%cd /content/models/mymodel\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .08', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .026666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDySP7TLzdCM"
      },
      "source": [
        "(Optional) If you're curious, you can display the configuration file's contents here in the browser by running the line of code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEsOLOMHzBqF"
      },
      "outputs": [],
      "source": [
        "# (Optional) Display the custom configuration file's contents\n",
        "!cat /content/models/mymodel/pipeline_file.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXpnXYC908Zl"
      },
      "source": [
        "Finally, let's set the locations of the configuration file and model output directory as variables so we can reference them when we call the training command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMlaN3rs3zLe"
      },
      "outputs": [],
      "source": [
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.&nbsp;Train Custom TFLite Detection Model"
      ],
      "metadata": {
        "id": "-19zML6oEO7l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPj_QV43qD5"
      },
      "source": [
        "We're ready to train our object detection model! Before we start training, let's load up a TensorBoard session to monitor training progress. Run the following section of code, and a TensorBoard session will appear in the browser. It won't show anything yet, because we haven't started training. Once training starts, come back and click the refresh button to see the model's overall loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI9iCCxoNlAL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cuQpPJL2pUq"
      },
      "source": [
        "Model training is performed using the \"model_main_tf2.py\" script from the TF Object Detection API. Training will take anywhere from 2 to 6 hours, depending on the model, batch size, and number of training steps. We've already defined all the parameters and arguments used by `model_main_tf2.py` in previous sections of this Colab. Just click Play on the following block to begin training!\n",
        "\n",
        "\n",
        "\n",
        "> *Note: It takes a few minutes for the program to display any training messages, because it only displays logs once every 100 steps. If it seems like nothing is happening, just wait a couple minutes.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQTfZChVzzpZ"
      },
      "outputs": [],
      "source": [
        "# Run training!\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to stop training early, just click Stop a couple times or right-click on the code block and select \"Interrupt Execution\". Otherwise, training will stop by itself once it reaches the specified number of training steps.\n"
      ],
      "metadata": {
        "id": "WHxbX4ZpzXIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.&nbsp;Convert Model to TensorFlow Lite"
      ],
      "metadata": {
        "id": "kPg8oMnQDYKl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spQXdq8Y63pj"
      },
      "source": [
        "Alright! Our model is all trained up and ready to be used for detecting objects. First, we need to export the model graph (a file that contains information about the architecture and weights) to a TensorFlow Lite-compatible format. We'll do this using the `export_tflite_graph_tf2.py` script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUU8tBlHifd"
      },
      "outputs": [],
      "source": [
        "# Make a directory to store the trained TFLite model\n",
        "!mkdir /content/custom_model_lite\n",
        "output_directory = '/content/custom_model_lite'\n",
        "\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = '/content/training'\n",
        "\n",
        "!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_NuapO2VROu"
      },
      "source": [
        "Next, we'll take the exported graph and use the `TFLiteConverter` module to convert it to `.tflite` FlatBuffer format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsE_uVjlsz3u"
      },
      "outputs": [],
      "source": [
        "# Convert exported graph file into TFLite model file\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/custom_model_lite/detect.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.&nbsp;Test TensorFlow Lite Model and Calculate mAP"
      ],
      "metadata": {
        "id": "RDQrtQhvC3oG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtSmUZcxIAvt"
      },
      "source": [
        "We've trained our custom model and converted it to TFLite format. But how well does it actually perform at detecting objects in images? This is where the images we set aside in the **test** folder come in. The model never saw any test images during training, so its performance on these images should be representative of how it will perform on new images from the field.\n",
        "\n",
        "### 7.1 Inference test images\n",
        "The following code defines a function to run inference on test images. It loads the images, loads the model and labelmap, runs the model on each image, and displays the result. It also optionally saves detection results as text files so we can use them to calculate model mAP score.\n",
        "\n",
        "This code is based off the [TFLite_detection_image.py](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py) script from my [TensorFlow Lite Object Detection repository on GitHub](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi); feel free to use it as a starting point for your own application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4WtI8i5K96w"
      },
      "outputs": [],
      "source": [
        "# Script to run custom TFLite model on test images to detect objects\n",
        "# Source: https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py\n",
        "\n",
        "# Import packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import importlib.util\n",
        "from tensorflow.lite.python.interpreter import Interpreter\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "### Define function for inferencing with TFLite model and displaying results\n",
        "\n",
        "def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):\n",
        "\n",
        "  # Grab filenames of all images in test folder\n",
        "  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n",
        "\n",
        "  # Load the label map into memory\n",
        "  with open(lblpath, 'r') as f:\n",
        "      labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "  # Load the Tensorflow Lite model into memory\n",
        "  interpreter = Interpreter(model_path=modelpath)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Get model details\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  height = input_details[0]['shape'][1]\n",
        "  width = input_details[0]['shape'][2]\n",
        "\n",
        "  float_input = (input_details[0]['dtype'] == np.float32)\n",
        "\n",
        "  input_mean = 127.5\n",
        "  input_std = 127.5\n",
        "\n",
        "  # Randomly select test images\n",
        "  images_to_test = random.sample(images, num_test_images)\n",
        "\n",
        "  # Loop over every image and perform detection\n",
        "  for image_path in images_to_test:\n",
        "\n",
        "      # Load image and resize to expected shape [1xHxWx3]\n",
        "      image = cv2.imread(image_path)\n",
        "      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      imH, imW, _ = image.shape\n",
        "      image_resized = cv2.resize(image_rgb, (width, height))\n",
        "      input_data = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "      # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
        "      if float_input:\n",
        "          input_data = (np.float32(input_data) - input_mean) / input_std\n",
        "\n",
        "      # Perform the actual detection by running the model with the image as input\n",
        "      interpreter.set_tensor(input_details[0]['index'],input_data)\n",
        "      interpreter.invoke()\n",
        "\n",
        "      # Retrieve detection results\n",
        "      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n",
        "      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n",
        "      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n",
        "\n",
        "      detections = []\n",
        "\n",
        "      # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
        "      for i in range(len(scores)):\n",
        "          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
        "\n",
        "              # Get bounding box coordinates and draw box\n",
        "              # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
        "              ymin = int(max(1,(boxes[i][0] * imH)))\n",
        "              xmin = int(max(1,(boxes[i][1] * imW)))\n",
        "              ymax = int(min(imH,(boxes[i][2] * imH)))\n",
        "              xmax = int(min(imW,(boxes[i][3] * imW)))\n",
        "\n",
        "              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
        "\n",
        "              # Draw label\n",
        "              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
        "              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
        "              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
        "              label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
        "              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
        "              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n",
        "\n",
        "              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
        "\n",
        "\n",
        "      # All the results have been drawn on the image, now display the image\n",
        "      if txt_only == False: # \"text_only\" controls whether we want to display the image results or just save them in .txt files\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        plt.figure(figsize=(12,16))\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "\n",
        "      # Save detection results in .txt files (for calculating mAP)\n",
        "      elif txt_only == True:\n",
        "\n",
        "        # Get filenames and paths\n",
        "        image_fn = os.path.basename(image_path)\n",
        "        base_fn, ext = os.path.splitext(image_fn)\n",
        "        txt_result_fn = base_fn +'.txt'\n",
        "        txt_savepath = os.path.join(savepath, txt_result_fn)\n",
        "\n",
        "        # Write results to text file\n",
        "        # (Using format defined by https://github.com/Cartucho/mAP, which will make it easy to calculate mAP)\n",
        "        with open(txt_savepath,'w') as f:\n",
        "            for detection in detections:\n",
        "                f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next block sets the paths to the test images and models and then runs the inferencing function. If you want to use more than 10 images, change the `images_to_test` variable. Click play to run inferencing!"
      ],
      "metadata": {
        "id": "-CJI4A0f_zqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up variables for running user's model\n",
        "PATH_TO_IMAGES='/content/images/test'   # Path to test images folder\n",
        "PATH_TO_MODEL='/content/custom_model_lite/detect.tflite'   # Path to .tflite model file\n",
        "PATH_TO_LABELS='/content/labelmap.txt'   # Path to labelmap.txt file\n",
        "min_conf_threshold=0.5   # Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n",
        "images_to_test = 10   # Number of images to run detection on\n",
        "\n",
        "# Run inferencing function!\n",
        "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"
      ],
      "metadata": {
        "id": "6t8CMarqBqP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Calculate mAP\n",
        "Now we have a visual sense of how our model performs on test images, but how can we quantitatively measure its accuracy?\n",
        "\n",
        "One popular methord for measuring object detection model accuracy is \"mean average precision\" (mAP). Basically, the higher the mAP score, the better your model is at detecting objects in images. To learn more about mAP, read through this [article from Roboflow](https://blog.roboflow.com/mean-average-precision/).\n",
        "\n",
        "We'll use the mAP calculator tool at https://github.com/Cartucho/mAP to determine our model's mAP score. First, we need to clone the repository and remove its existing example data. We'll also download a script I wrote for interfacing with the calculator."
      ],
      "metadata": {
        "id": "N_ckqeWqBF0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone https://github.com/Cartucho/mAP /content/mAP\n",
        "cd /content/mAP\n",
        "rm input/detection-results/*\n",
        "rm input/ground-truth/*\n",
        "rm input/images-optional/*\n",
        "wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/calculate_map_cartucho.py"
      ],
      "metadata": {
        "id": "JlWarXEZDUqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll copy the images and annotation data from the **test** folder to the appropriate folders inside the cloned repository. These will be used as the \"ground truth data\" that our model's detection results will be compared to.\n"
      ],
      "metadata": {
        "id": "qn22nGGqH5T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/images/test/* /content/mAP/input/images-optional # Copy images and xml files\n",
        "!mv /content/mAP/input/images-optional/*.xml /content/mAP/input/ground-truth/  # Move xml files to the appropriate folder"
      ],
      "metadata": {
        "id": "5szFfVxwI3wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The calculator tool expects annotation data in a format that's different from the Pascal VOC .xml file format we're using. Fortunately, it provides an easy script, `convert_gt_xml.py`, for converting to the expected .txt format.\n",
        "\n"
      ],
      "metadata": {
        "id": "u6aro817DGzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/mAP/scripts/extra/convert_gt_xml.py"
      ],
      "metadata": {
        "id": "qdjtOUDnK2AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, we've set up the ground truth data, but now we need actual detection results from our model. The detection results will be compared to the ground truth data to calculate the model's accuracy in mAP.\n",
        "\n",
        "The inference function we defined in Step 7.1 can be used to generate detection data for all the images in the **test** folder. We'll use it the same as before, except this time we'll tell it to save detection results into the `detection-results` folder.\n",
        "\n",
        "Click Play to run the following code block!"
      ],
      "metadata": {
        "id": "mnIUacAlLP0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up variables for running inference, this time to get detection results saved as .txt files\n",
        "PATH_TO_IMAGES='/content/images/test'   # Path to test images folder\n",
        "PATH_TO_MODEL='/content/custom_model_lite/detect.tflite'   # Path to .tflite model file\n",
        "PATH_TO_LABELS='/content/labelmap.txt'   # Path to labelmap.txt file\n",
        "PATH_TO_RESULTS='/content/mAP/input/detection-results' # Folder to save detection results in\n",
        "min_conf_threshold=0.1   # Confidence threshold\n",
        "\n",
        "# Use all the images in the test folder\n",
        "image_list = glob.glob(PATH_TO_IMAGES + '/*.jpg') + glob.glob(PATH_TO_IMAGES + '/*.JPG') + glob.glob(PATH_TO_IMAGES + '/*.png') + glob.glob(PATH_TO_IMAGES + '/*.bmp')\n",
        "images_to_test = min(500, len(image_list)) # If there are more than 500 images in the folder, just use 500\n",
        "\n",
        "# Tell function to just save results and not display images\n",
        "txt_only = True\n",
        "\n",
        "# Run inferencing function!\n",
        "print('Starting inference on %d images...' % images_to_test)\n",
        "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test, PATH_TO_RESULTS, txt_only)\n",
        "print('Finished inferencing!')"
      ],
      "metadata": {
        "id": "szzHFAhsMNFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's calculate mAP! One popular style for reporting mAP is the COCO metric for mAP @ 0.50:0.95. Basically, this means that mAP is calculated at several IoU thresholds between 0.50 and 0.95, and then the result from each threshold is averaged to get a final mAP score. [Learn more here!](https://blog.roboflow.com/mean-average-precision/)\n",
        "\n",
        "I wrote a script to run the calculator tool at each IoU threshold, average the results, and report the final accuracy score. It reports mAP for each class and overall mAP. Click Play on the following two blocks to calculate mAP!"
      ],
      "metadata": {
        "id": "e_QRnTqNPX4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mAP\n",
        "!python calculate_map_cartucho.py --labels=/content/labelmap.txt"
      ],
      "metadata": {
        "id": "3DkjpIBARTQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score reported at the end is your model's overall mAP score. Ideally, it should be above 50% (0.50). If it isn't, you can increase your model's accuracy by adding more images to your dataset. See my [dataset video](https://www.youtube.com/watch?v=v0ssiOY6cfg) for tips on how to capture good training images and improve accuracy."
      ],
      "metadata": {
        "id": "R9HPoOBVKvxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.&nbsp;Deploy TensorFlow Lite Model"
      ],
      "metadata": {
        "id": "5i40ve0SCLaE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phT8vvzriqQp"
      },
      "source": [
        "Now that your custom model has been trained and converted to TFLite format, it's ready to be downloaded and deployed in an application! This section shows how to download the model and provides links to instructions for deploying it on the Raspberry Pi, your PC, or other edge devices."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1. Download TFLite model\n",
        "\n",
        "Run the two following cells to copy the labelmap files into the model folder, compress it into a zip folder, and then download it. The zip folder contains the `detect.tflite` model and `labelmap.txt` labelmap files that are needed to run the model in your application."
      ],
      "metadata": {
        "id": "zq3L2IoP4VHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awZMQGVqMpVL"
      },
      "outputs": [],
      "source": [
        "# Move labelmap and pipeline config files into TFLite model folder and zip it up\n",
        "!cp /content/labelmap.txt /content/custom_model_lite\n",
        "!cp /content/labelmap.pbtxt /content/custom_model_lite\n",
        "!cp /content/models/mymodel/pipeline_file.config /content/custom_model_lite\n",
        "\n",
        "%cd /content\n",
        "!zip -r custom_model_lite.zip custom_model_lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVPfAGbNPV56"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/custom_model_lite.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `custom_model_lite.zip` file containing the model will download into your Downloads folder. It's ready to be deployed on your device!"
      ],
      "metadata": {
        "id": "9Kb3ZBsMq95l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSJ2wgGCixy2"
      },
      "source": [
        "## 8.2. Deploy model\n",
        "TensorFlow Lite models can run on a wide variety of hardware, including PCs, embedded systems, and phones. This section provides instructions showing how to deploy your TFLite model on various devices.\n",
        "\n",
        "### 8.2.1. Deploy on Raspberry Pi\n",
        "TFLite models are great for running on the Raspberry Pi, because they require less processing power than regular TensorFlow vision models. The Pi can run TFLite models in near real-time.\n",
        "\n",
        "To run your new model on the Raspberry Pi, you'll have to install TensorFlow Lite and prepare a Python environment for your application. I provide step-by-step instructions on how to set up TFLite on the Pi in my video, [How To Run TensorFlow Lite on Raspberry Pi for Object Detection](https://youtu.be/aimSGOAUI8Y).\n",
        "\n",
        "[![Link to my YouTube video!](https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/doc/YouTube_video1.JPG)](https://www.youtube.com/watch?v=aimSGOAUI8Y)\n",
        "\n",
        "Once you've completed all the steps in the video, move the `custom_model_lite.zip` file downloaded from this Colab session over to your Raspberry Pi into the `~/tflite1` folder. Move into the folder and unzip it by issuing:\n",
        "\n",
        "```\n",
        "cd ~/tflite1\n",
        "unzip custom_model_lite.zip\n",
        "```\n",
        "\n",
        "Then, run the image, video, or webcam TFLite detection program with the `--modeldir=fine_tuned_model_lite` argument. For example, to run the webcam detection program, issue:\n",
        "\n",
        "```\n",
        "python TFLite_detection_webcam.py --modeldir=custom_model_lite\n",
        "```\n",
        "\n",
        "A window will appear showing a live feed from your webcam with boxes drawn around detected objects in each frame.\n",
        "\n",
        "### 8.2.2. Deploy on Windows, Linux, or macOS\n",
        "Follow the instructions linked below to quickly set up your Windows, Linux, or macOS computer to run TFLite models. It only takes a few minutes! Running a model on your PC is good for quickly testing your model with a webcam. However, keep in mind that the TFLite Runtime is optimized for lower-power processors, and it won't utilize the full capability of your PC's processor.\n",
        "\n",
        "Here are links to the deployment guides for Windows, Linux, and macOS:\n",
        "* [How to Run TensorFlow Lite Models on Windows](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Windows_TFLite_Guide.md)\n",
        "* *link to Linux guide to be added (but really it's the same as Raspberry Pi)*\n",
        "* [How to Run TensorFlow Lite Models on macOS](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/MacOS_TFLite_Guide.md)\n",
        "\n",
        "### 8.2.3. Deploy on other Linux-based edge devices\n",
        "Instructions to be added! 🐧\n",
        "\n",
        "### 8.2.4. Deploy on Android\n",
        "Instructions to be added! 🤖\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.&nbsp;(Optional) Post-Training Quantization"
      ],
      "metadata": {
        "id": "WoptFnAhCSrR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I54paUm8dUCr"
      },
      "source": [
        "Want to make your TFLite model run even faster? Quantize it! Quantizating a model converts its weights from 32-bit floating-point values to 8-bit integer values. This allows the quantized model to run faster and occupy less memory without too much reduction in accuracy.\n",
        "\n",
        "> Note: If you observe an obvious decrease in detection accuracy when quantizing your model with TF2, I recommend using TensorFlow 1 to quantize your model instead. TF1 supports quantization-aware training, which helps improve the accuracy of quantized models. The ssd-mobilenet-v2-quantized model from the TF1 Model Zoo has fast and accurate performance when trained with a custom dataset. Visit my [TFLite v1 Colab notebook](https://colab.research.google.com/github/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Train_TFLite1_Object_Detection_Model.ipynb) for step-by-step instructions on how to train and quantize a model with TensorFlow 1."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.1. Quantize model\n",
        "We'll use the \"TFLiteConverter\" module to perform [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) on the model. To quantize the model, we need to provide a representative dataset, which is a set of images that represent what the model will see when deployed in the field. First, we'll create a list of images to include in the representative dataset (we'll just use the images in the `train` folder).\n"
      ],
      "metadata": {
        "id": "VTyqlXFTJ0Uv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNZtfj_k3NP"
      },
      "outputs": [],
      "source": [
        "# Get list of all images in train directory\n",
        "image_path = '/content/images/train'\n",
        "\n",
        "jpg_file_list = glob.glob(image_path + '/*.jpg')\n",
        "JPG_file_list = glob.glob(image_path + '/*.JPG')\n",
        "png_file_list = glob.glob(image_path + '/*.png')\n",
        "bmp_file_list = glob.glob(image_path + '/*.bmp')\n",
        "\n",
        "quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll define a function to yield images from our representative dataset. Refer to [TensorFlow's sample quantization code](https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb#scrollTo=kRDabW_u1wnv) to get a better understanding of what this is doing!"
      ],
      "metadata": {
        "id": "cqbH1VlEgiuy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORzx0XRErSLV"
      },
      "outputs": [],
      "source": [
        "# A generator that provides a representative dataset\n",
        "# Code modified from https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
        "\n",
        "# First, get input details for model so we know how to preprocess images\n",
        "interpreter = Interpreter(model_path=PATH_TO_MODEL) # PATH_TO_MODEL is defined in Step 7 above\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "height = input_details[0]['shape'][1]\n",
        "width = input_details[0]['shape'][2]\n",
        "\n",
        "import random\n",
        "\n",
        "def representative_data_gen():\n",
        "  dataset_list = quant_image_list\n",
        "  quant_num = 300\n",
        "  for i in range(quant_num):\n",
        "    pick_me = random.choice(dataset_list)\n",
        "    image = tf.io.read_file(pick_me)\n",
        "\n",
        "    if pick_me.endswith('.jpg') or pick_me.endswith('.JPG'):\n",
        "      image = tf.io.decode_jpeg(image, channels=3)\n",
        "    elif pick_me.endswith('.png'):\n",
        "      image = tf.io.decode_png(image, channels=3)\n",
        "    elif pick_me.endswith('.bmp'):\n",
        "      image = tf.io.decode_bmp(image, channels=3)\n",
        "\n",
        "    image = tf.image.resize(image, [width, height])  # TO DO: Replace 300s with an automatic way of reading network input size\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtu98mzebEj"
      },
      "source": [
        "Finally, we'll initialize the TFLiteConverter module, point it at the TFLite graph we generated in Step 6, and provide it with the representative dataset generator function we created in the previous code block. We'll configure the converter to quantize the model's weight values to INT8 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox0bGDWds_Ce"
      },
      "outputs": [],
      "source": [
        "# Initialize converter module\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n",
        "\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This sets the representative dataset for quantization\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input tensors to uint8 and output tensors to float32\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.float32\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/custom_model_lite/detect_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.2. Test quantized model\n",
        "The model has been quantized and exported as `detect_quant.tflite`. Let's test it out! We'll re-use the function from Section 7 for running the model on test images and display the results, except this time we'll point it at the quantized model.\n",
        "\n",
        "Click Play on the code block below to test the `detect_quant.tflite` model."
      ],
      "metadata": {
        "id": "dYVVlv5QUUZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up parameters for inferencing function (using detect_quant.tflite instead of detect.tflite)\n",
        "PATH_TO_IMAGES='/content/images/test'   #Path to test images folder\n",
        "PATH_TO_MODEL='/content/custom_model_lite/detect_quant.tflite'   #Path to .tflite model file\n",
        "PATH_TO_LABELS='/content/labelmap.txt'   #Path to labelmap.txt file\n",
        "min_conf_threshold=0.5   #Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n",
        "images_to_test = 10   #Number of images to run detection on\n",
        "\n",
        "# Run inferencing function!\n",
        "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"
      ],
      "metadata": {
        "id": "6OoirJuOtdOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your quantized model isn't performing very well, try using my TensorFlow Lite 1 notebook *(link to be added)* to train a SSD-MobileNet model with your dataset. In my experience, the `ssd-mobilenet-v2-quantized` model from the [TF1 Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md) has the best quantized performance out of any other TensorFlow Lite model.\n",
        "\n",
        "TFLite models created with TensorFlow 1 are still compatible with the TensorFlow Lite 2 runtime, so your TFLite 1 model will still work with my [TensorFlow setup guide for the Raspberry Pi](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md)."
      ],
      "metadata": {
        "id": "cKo7ZtfOyoxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.3 Calculate quantized model mAP\n",
        "\n",
        "Let's calculate the quantize model's mAP using the calculator tool we set up in Step 7.2. We just need to perform inference with our quantized model (`detect_quant.tflite`) to get a new set of detection results.\n",
        "\n",
        "Run the following block to run inference on the test images and save the detection results."
      ],
      "metadata": {
        "id": "vWdVxs6LUjbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to remove existing detection results first\n",
        "!rm /content/mAP/input/detection-results/*\n",
        "\n",
        "# Set up variables for running inference, this time to get detection results saved as .txt files\n",
        "PATH_TO_IMAGES='/content/images/test'   # Path to test images folder\n",
        "PATH_TO_MODEL='/content/custom_model_lite/detect_quant.tflite'   # Path to quantized .tflite model file\n",
        "PATH_TO_LABELS='/content/labelmap.txt'   # Path to labelmap.txt file\n",
        "PATH_TO_RESULTS='/content/mAP/input/detection-results' # Folder to save detection results in\n",
        "min_conf_threshold=0.1   # Confidence threshold\n",
        "\n",
        "# Use all the images in the test folder\n",
        "image_list = glob.glob(PATH_TO_IMAGES + '/*.jpg') + glob.glob(PATH_TO_IMAGES + '/*.JPG') + glob.glob(PATH_TO_IMAGES + '/*.png') + glob.glob(PATH_TO_IMAGES + '/*.bmp')\n",
        "images_to_test = min(500, len(image_list)) # If there are more than 500 images in the folder, just use 500\n",
        "\n",
        "# Tell function to just save results and not display images\n",
        "txt_only = True\n",
        "\n",
        "# Run inferencing function!\n",
        "print('Starting inference on %d images...' % images_to_test)\n",
        "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test, PATH_TO_RESULTS, txt_only)\n",
        "print('Finished inferencing!')"
      ],
      "metadata": {
        "id": "ZMaumV-11Et0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can run the mAP calculation script to determine our quantized model's mAP."
      ],
      "metadata": {
        "id": "QgcmdLQf1Et1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/mAP"
      ],
      "metadata": {
        "id": "ZIRNp0Af1Et1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python calculate_map_cartucho.py --labels=/content/labelmap.txt"
      ],
      "metadata": {
        "id": "4TDgMBw_1Et1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFsuasvxFHo8"
      },
      "source": [
        "## 9.4. Compile model for Edge TPU\n",
        "\n",
        "Now that the model has been converted to TFLite and quantized, we can compile it to run on Edge TPU devices like the [Coral USB Accelerator](https://coral.ai/products/accelerator/) or the [Coral Dev Board](https://coral.ai/products/dev-board/). This allows the model to run much faster! For information on how to set up the USB Accelerator, my [TensorFlow Lite repository on GitHub](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Raspberry_Pi_Guide.md#section-2---run-edge-tpu-object-detection-models-on-the-raspberry-pi-using-the-coral-usb-accelerator).\n",
        "\n",
        "First, install the Edge TPU Compiler package inside this Colab instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUd_SNC0JSq0"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "! sudo apt-get update\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usfmdtSiJuuC"
      },
      "source": [
        "Next, compile the quantize TFLite model. (If your model has a different filename than \"detect_quant.tflite\", use that instead.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mULCY0nb0ahH"
      },
      "outputs": [],
      "source": [
        "%cd /content/custom_model_lite\n",
        "!edgetpu_compiler detect_quant.tflite\n",
        "!mv detect_quant_edgetpu.tflite edgetpu.tflite\n",
        "!rm detect_quant_edgetpu.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGy2FgzKomN"
      },
      "source": [
        "The compiled model will be output in the `custom_model_lite` folder as \"detect__quant_edgetpu.tflite\". It gets renamed to \"edgetpu.tflite\" to be consistent with my code. Zip the `custom_model_lite` folder and download it by running the two code blocks below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nCdUouYJjQM"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!zip -r custom_model_lite.zip custom_model_lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmjqvKuuK8ZR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('custom_model_lite.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptwpBBEWLfuJ"
      },
      "source": [
        "Now you're all set to use the Coral model! For instructions on how to run an object detection model on the Raspberry Pi using the Coral USB Acclerator, please see my video, [\"How to Use the Coral USB Accelerator with the Raspberry Pi\"](https://www.youtube.com/watch?v=qJMwNHQNOVU)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix: Common Errors"
      ],
      "metadata": {
        "id": "5VI_Gh5dCd7w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEbd9cO7I_o3"
      },
      "source": [
        "Here are solutions to common errors that can occur while stepping through this notebook.\n",
        "\n",
        "**1. Training suddenly stops with ^C output**\n",
        "\n",
        "If your training randomly stops without any error messages except a `^C`, that means the virtual machine has run out of memory. To resolve the issue, try reducing the `batch_size` variable in Step 4 to a lower value like `batch_size = 4`. The value must be a power of 2. (e.g. 2, 4, 8 ...)\n",
        "\n",
        "Source: https://stackoverflow.com/questions/75901898/why-my-model-training-automatically-stopped-during-training"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4VAvZo8qE4u5",
        "sxb8_h-QFErO",
        "eydREUsMGUUR",
        "eGEUZYAMEZ6f",
        "-19zML6oEO7l",
        "kPg8oMnQDYKl",
        "RDQrtQhvC3oG",
        "5i40ve0SCLaE",
        "WoptFnAhCSrR",
        "5VI_Gh5dCd7w"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}